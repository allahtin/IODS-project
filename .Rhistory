mat_data<-read.csv("data/student-mat.csv")
View(mat_data)
mat_data<-read.csv("data/student-mat.csv", header=T, sep=";")
View(mat_data)
dim(mat_data)
head(mat_data)
str(mat_data)
por_data<-read.csv("data/student-por.csv", header=T, sep=";")
dim(por_data)#has 395 rows, 33 columns
head(por_data)#looks like a data on two high schools' students with gender,ages and other info on family
View(por_data)
str(por_data)#tells what variables are in columns: integer, factors etc
library(dplyr)
join_by <- c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet")
math_por <- inner_join(mat_data, por_data, by = join_by)
View(math_por)
dim(math_por)
head(math_por)
alc <- select(math_por, one_of(join_by))
notjoined_columns <- colnames(math)[!colnames(math) %in% join_by]
notjoined_columns <- colnames(mat_data)[!colnames(mat_data) %in% join_by]
for(column_name in notjoined_columns) {
# select two columns from 'math_por' with the same original name
two_columns <- select(math_por, starts_with(column_name))
# select the first column vector of those two columns
first_column <- select(two_columns, 1)[[1]]
# if that first column vector is numeric...
if(is.numeric(first_column)) {
# take a rounded average of each row of the two columns and
# add the resulting vector to the alc data frame
alc[column_name] <- round(rowMeans(two_columns))
} else { # else if it's not numeric...
# add the first column vector to the alc data frame
alc[column_name] <- first_column
}
}
alc <- mutate(alc, alc_use = (Dalc + Walc) / 2)
View(alc)
alc <- mutate(alc, alc_use = (Dalc + Walc) / 2)
alc <- mutate(alc, high_use = alc_use > 2)
dim(alc)
glimpse(alc)
?write.csv()
write.csv(alc, "Joined student alcohol consumption data.csv", sep=";")
joined_data<-read.csv("Joined student alcohol consumption data.csv", header=T, sep=";")
View(joined_data)
write.csv(alc, "Joined student alcohol consumption data.csv")
joined_data<-read.csv("Joined student alcohol consumption data.csv", header=T, sep=";")
View(joined_data)
write.table(alc, "Joined student alcohol consumption data.txt")
joined_data<-read.table("Joined student alcohol consumption data.txt", header=T)
View(joined_data)
View(alc)
joined_data<-read.table("Joined student alcohol consumption data.txt", header=T)
View(joined_data)
head(joined_data)
joined_data<-read.table("Joined student alcohol consumption data.txt", header=T)
dim(joined_data)
head(joined_data)
```{r}
joined_data<-read.table("Joined student alcohol consumption data.txt", header=T)
dim(joined_data)
glimpse(joined_data)
library(dplyr)
joined_data<-read.table("Joined student alcohol consumption data.txt", header=T)
dim(joined_data)
glimpse(joined_data)
View(joined_data)
library(ggplot2)
gather(joined_data) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()
library(ggplot2)
library(tidyr)
gather(joined_data) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()
library(ggplot2)
alc %>% group_by(sex) %>% summarise(count = n())
library(ggplot2)
joined_data %>% group_by(sex) %>% summarise(count = n())
joined_data %>% group_by(sex) %>% summarise(count = n())
joined_data %>% group_by(age) %>% summarise(count = n())
joined_data %>% group_by(sex) %>% summarise(count = n())
joined_data %>% group_by(age) %>% summarise(count = n())
joined_data %>% group_by(internet) %>% summarise(count = n())
library(ggplot2)
g1 <- ggplot(alc, aes(x = high_use, y = G3))
g1 + geom_boxplot() + ylab("sex")
library(ggplot2)
g1 <- ggplot(alc, aes(x = high_use, y = sex))
g1 + geom_boxplot() + ylab("sex")
library(ggplot2)
g1 <- ggplot(alc, aes(x = high_use, y = age))
g1 + geom_boxplot() + ylab("age")
library(ggplot2)
g1 <- ggplot(alc, aes(x = high_use, y = sex))
g1 + geom_bar() + ylab("sex")
library(ggplot2)
g1 <- ggplot(alc, aes(x = high_use, y = sex))
g1 + geom_bar(stat="sex") + ylab("sex")
library(ggplot2)
g1 <- ggplot(joined_data, aes(x = high_use, y = sex))
g1 + geom_bar(stat="sex") + ylab("sex")
View(joined_data)
g1 + geom_bar(stat=sex) + ylab("sex")
library(ggplot2)
g1 <- ggplot(joined_data, aes(x = high_use, y = sex))
g1 + geom_bar(stat=sex) + ylab("sex")
library(ggplot2)
g1 <- ggplot(joined_data, aes(high_use))
g1 <- ggplot(joined_data, aes(high_use))
g1
library(ggplot2)
g1 <- ggplot(joined_data, aes(high_use))
g1
g1 + geom_bar(aes(fill=sex))
g1 + geom_bar(aes(fill=sex))
library(ggplot2)
g1 <- ggplot(joined_data, aes(high_use))
g1 + geom_bar(aes(fill=internet))
m <- glm(high_use ~ age + sex + internet, data = joined_data, family = "binomial")
summary(m)
coef(m)
OR <- coef(m) %>% exp
CI <- confint(m) %>% exp
cbind(OR, CI)
library(dplyr)
m <- glm(high_use ~ age + sex + internet, data = joined_data, family = "binomial")
probabilities <- predict(m, type = "response")
joined_data <- mutate(joined_data, probability = probabilities)
joined_data <- mutate(joined_data, prediction = probability > 0.5)
select(joined_data, failures, absences, sex, high_use, probability, prediction) %>% tail(10)
table(high_use = joined_data$high_use, prediction = joined_data$prediction)
library(dplyr)
library(ggplot2)
g <- ggplot(joined_data, aes(x = probability, y = high_use, col = prediction))
g + geom_point()
table(high_use = joined_data$high_use, prediction = joined_data$prediction) %>% prop.table %>% addmargins
loss_func <- function(class, prob) {
n_wrong <- abs(class - prob) > 0.5
mean(n_wrong)
}
loss_func(class = joined_data$high_use, prob = 0)
library(boot)
cv <- cv.glm(data = joined_data, cost = loss_func, glmfit = m, K = 10)
cv$delta[1]
View(joined_data)
joined_data %>% group_by(sex) %>% summarise(count = n())
joined_data %>% group_by(age) %>% summarise(count = n())
joined_data %>% group_by(internet) %>% summarise(count = n())
joined_data %>% group_by(absences) %>% summarise(count = n())
library(ggplot2)
g1 <- ggplot(joined_data, aes(x = high_use, y = absences))
g1 + geom_boxplot() + ylab("absences")
m <- glm(high_use ~ age + sex + internet+absences, data = joined_data, family = "binomial")
summary(m)
coef(m)
OR <- coef(m) %>% exp
CI <- confint(m) %>% exp
cbind(OR, CI)
library(dplyr)
m <- glm(high_use ~ age + sex + internet + absences, data = joined_data, family = "binomial")
probabilities <- predict(m, type = "response")
joined_data <- mutate(joined_data, probability = probabilities)
joined_data <- mutate(joined_data, prediction = probability > 0.5)
select(joined_data, failures, absences, sex, high_use, probability, prediction) %>% tail(10)
table(high_use = joined_data$high_use, prediction = joined_data$prediction)
library(dplyr)
library(ggplot2)
g <- ggplot(joined_data, aes(x = probability, y = high_use, col = prediction))
g + geom_point()
table(high_use = joined_data$high_use, prediction = joined_data$prediction) %>% prop.table %>% addmargins
loss_func <- function(class, prob) {
n_wrong <- abs(class - prob) > 0.5
mean(n_wrong)
}
loss_func(class = joined_data$high_use, prob = 0)
library(boot)
cv <- cv.glm(data = joined_data, cost = loss_func, glmfit = m, K = 10)
cv$delta[1]
library(dplyr)
m <- glm(high_use ~ age + sex + internet + absences, data = joined_data, family = "binomial")
probabilities <- predict(m, type = "response")
joined_data <- mutate(joined_data, probability = probabilities)
joined_data <- mutate(joined_data, prediction = probability > 0.5)
select(joined_data, age, internet, absences, sex, high_use, probability, prediction) %>% tail(10)
table(high_use = joined_data$high_use, prediction = joined_data$prediction)
library(dplyr)
library(ggplot2)
g <- ggplot(joined_data, aes(x = probability, y = high_use, col = prediction))
g + geom_point()
table(high_use = joined_data$high_use, prediction = joined_data$prediction) %>% prop.table %>% addmargins
loss_func <- function(class, prob) {
n_wrong <- abs(class - prob) > 0.5
mean(n_wrong)
}
loss_func(class = joined_data$high_use, prob = 0)
library(devtools)
install_version('rmarkdown', version = '1.8')
setwd("C:/Users/ELITEBOOK/Dropbox/CLINICALDATAMINING2018/Exercises/EX3")
setwd("C:/Users/ELITEBOOK/Dropbox/CLINICALDATAMINING2018/Exercises/EX3")
setwd("C:/Users/ELITEBOOK/Desktop/EX3")
library(readxl)
library(survival)
library(survminer)
library(dplyr)
df1 <- read_excel("datafileex3.xlsx", sheet = 9)
df2<-  filter(df1, `Included in Survival Analysis` == "Yes")
df3<-select(df2,followUp  = `Follow_up Time _yrs`,
status    = `Status at Follow_up_ 0 Alive_ 1 Dead`,
IPI_Group = `IPI Group`,
subtype   = `Gene Expression Subgroup`,
Genetic_Subtype = `Genetic Subtype`,
everything())
str(df3)
df4<-mutate(df3, IPI_Group = factor(IPI_Group, levels = c("Low","Intermediate","High")),
subtype = factor(subtype, levels = c("GCB","ABC","Unclass")),
Genetic_Subtype = factor(Genetic_Subtype, levels = c("Other","BN2","MCD","N1","EZB")))
str(df4)
survivalFitIPI <- survfit(Surv(followUp,status) ~ IPI_Group, data = df4)
ggsurvplot(survivalFitIPI, data = df4, pval = TRUE)
survivalFitSubtype <- survfit(Surv(followUp,status) ~ subtype, data = df4)
ggsurvplot(survivalFitSubtype, data = df4, pval = TRUE)
survivalFitGeneticSubtype <- survfit(Surv(followUp,status) ~ Genetic_Subtype, data = df4)
ggsurvplot(survivalFitGeneticSubtype, data = df4, pval = TRUE)
survivalDiffIPI <- survdiff(Surv(followUp,status) ~ IPI_Group, data = df4)#Tests if there is a difference between
survivalDiffIPI
survivalDiffSubtype <- survdiff(Surv(followUp,status) ~ subtype, data = df4)
survivalDiffSubtype
survivalDiffGeneticSubtype <- survdiff(Surv(followUp,status) ~ Genetic_Subtype, data = df4)
survivalDiffGeneticSubtype
coxModel <- coxph(Surv(followUp, status) ~ IPI_Group + subtype + Genetic_Subtype,data = df4)
summary(coxModel)
ggforest(coxModel, data = df4)
library(readxl)
library(survival)
library(survminer)
library(dplyr)
df1 <- read_excel("datafileex3.xlsx", sheet = 9)
df2<-  filter(df1, `Included in Survival Analysis` == "Yes")
df3<-select(df2,followUp  = `Follow_up Time _yrs`,
status    = `Status at Follow_up_ 0 Alive_ 1 Dead`,
IPI_Group = `IPI Group`,
subtype   = `Gene Expression Subgroup`,
Genetic_Subtype = `Genetic Subtype`,
everything())
str(df3)
df4<-mutate(df3, IPI_Group = factor(IPI_Group, levels = c("Low","Intermediate","High")),
subtype = factor(subtype, levels = c("GCB","ABC","Unclass")),
Genetic_Subtype = factor(Genetic_Subtype, levels = c("Other","BN2","MCD","N1","EZB")))
str(df4)
survivalFitIPI <- survfit(Surv(followUp,status) ~ IPI_Group, data = df4)
ggsurvplot(survivalFitIPI, data = df4, pval = TRUE)
View(df1)
getwd()
library(MASS)
df<-data("Boston")
glimpse(df)
str(df)
pairs(Boston)
Boston$crim %>% summary()
Boston$crim %>%
summary()
summary(Boston)
cor_matrix<-cor(Boston) %>% round(digits = 2)
library(dplyr)
cor_matrix<-cor(Boston) %>% round(digits = 2)
install.packages('corplot')
install.packages("corrplot")
boston_scaled <- scale(Boston)
class(Boston)
summary(boston_scaled)
?scale
boston_scaled <- scale(Boston)
summary(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)
boston_scaled <- scale(Boston)
summary(boston_scaled)
class(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)
class(boston_scaled)
summary(boston_scaled$crim)
bins <- quantile(boston_scaled$crim)
bins
summary(boston_scaled$crim)
bins <- quantile(boston_scaled$crim)
bins
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, labels = c("low", "med_low", "med_high", "high"))
View(boston_scaled)
boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)
View(boston_scaled)
boston_scaled <- dplyr::select(boston_scaled, -crim)
table(boston_scaled$crime)
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
correct_classes <- test$crime
test <- dplyr::select(test, -crime)
lda.fit <- lda(crime ~ ., data = train)
lda.fit
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "orange", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 1)
lda.pred <- predict(lda.fit, newdata = test)
table(correct = correct_classes, predicted = lda.pred$class)
View(Boston)
library(MASS)
data('Boston')
data("Boston")
View(Boston)
summary(Boston)
scale(Boston)
library(MASS)
data("Boston")
dist_eu <- dist(scale(Boston))
summary(dist_eu)
dist_man <- dist(scale(Boston, method = 'manhattan'))
dist_man <- dist(scale(Boston, method = "manhattan"))
dist_man <- dist(scale(Boston), method = "manhattan"))
dist_man <- dist(scale(Boston), method = "manhattan")
summary(dist_man)
km <-kmeans(Boston, centers = 3)
pairs(Boston, col = km$cluster)
k_max <- 10
twcss <- sapply(1:k_max, function(k){kmeans(Boston, k)$tot.withinss})
qplot(x = 1:k_max, y = twcss, geom = 'line')
k_max <- 10
twcss <- sapply(1:k_max, function(k){kmeans(Boston, k)$tot.withinss})
qplot(x = 1:k_max, y = twcss, geom = 'line')
?qplot
??qplot
library(ggplot2)
qplot(x = 1:k_max, y = twcss, geom = 'line')
km <-kmeans(Boston, centers = 2)
pairs(Boston, col = km$cluster)
model_predictors <- dplyr::select(train, -crime)
dim(model_predictors)
dim(lda.fit$scaling)
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling
matrix_product <- as.data.frame(matrix_product)
library(plotly)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers')
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
dim(hd)
dim(gii)
glimps(hd)
glimpse(hd)
glimpse(gii)
summary(hd)
summary(hd)
summary(gii)
colnames(hd)
names(hd)[1]<-"HDIRank"
View(hd)
names(hd)[3]<-"HDI"
names(hd)[4]<-"LE"
names(hd)[5]<-"EYEdu"
names(hd)[6]<-"MeanYedu"
names(hd)[4]<-"GNI"
names(hd)[4]<-"LE"
names(hd)[7]<-"GNI"
names(hd)[8]<-"GNIminusHDI"
View(hd)
colnames(gii)
names(GII)[3]<-"GII"
names(gii)[3]<-"GII"
names(gii)[7]<-"PopFemale"
names(gii)[8]<-"PopMale"
names(gii)[9]<-"LFPRFemale"
names(gii)[10]<-"LFPRMale"
View(gii)
gii$ratioedu<-gii$PopFemale/gii$PopMale
View(gii)
gii$ratiolabforce<-gii$LFPRFemale/gii$LFPRMale
View(gii)
joined<-innerjoin(hd, gii, by = Country, type = "left", match = "all")
joined<-inner_join(hd, gii, by = Country, type = "left", match = "all")
View(gii)
joined<-inner_join(hd, gii, by = "Country", type = "left", match = "all")
View(joined)
dim(joined)
View(joined)
getwd()
write.table(joined, file="C:/Users/ELITEBOOK/Documents/GitHub/IODS-project/data/human.txt")
joined_data<-read.table("C:/Users/ELITEBOOK/Documents/GitHub/IODS-project/data/human.txt", header=T)
View(joined_data)
